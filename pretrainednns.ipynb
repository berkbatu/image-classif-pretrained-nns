{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09 Neural Nets Pretrained Image Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnAa-QR1oeL4"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6NRfj76ojE8"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, decode_predictions, preprocess_input\n",
        "\n",
        "from IPython.core.display import display\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input as preprocess_input_vgg19\n",
        "from keras.applications.vgg19 import decode_predictions as decode_vgg19"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hinQ_rUorEsO"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC6dpJAhpSta"
      },
      "source": [
        "FILE_1 = 'baloons.jpg' #any names of the images you want to classify\n",
        "FILE_2 = 'car.jpg'\n",
        "FILE_3 = 'coffeemilk.jpg'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEuNV70OrSyD"
      },
      "source": [
        "# Preprocessing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_1UMxiYoEcq"
      },
      "source": [
        "pic = load_img(FILE_1, target_size=(299, 299))\n",
        "display(pic)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3UxVTLCug_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6babb2d4-2c66-4db1-9542-ffeb0450a5a8"
      },
      "source": [
        "pic_array = img_to_array(pic)\n",
        "pic_array.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(299, 299, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRpYb_1zc89Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4162ab18-c8c2-4abd-eff8-16dff44d3fa5"
      },
      "source": [
        "expanded = np.expand_dims(pic_array, axis=0)\n",
        "expanded.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 299, 299, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAoyAFSPdhkO"
      },
      "source": [
        "preprocessed = preprocess_input(expanded)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2gD7R4JhWSO"
      },
      "source": [
        "Function called ```format_img_inceptionresnet()``` that takes a filename as an argument. The function loads the image in the default resolution for InceptionResNetv2, converts the image to an array and returns the preprocessed image for the InceptionResNetv2 model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5rRYOWjjFrS"
      },
      "source": [
        "def format_img_inceptionresnet(filename):\n",
        "  pic = load_img(filename, target_size=(299,299))\n",
        "  pic_arr = img_to_array(pic)\n",
        "  expanded = np.expand_dims(pic_arr, axis=0)\n",
        "  return preprocess_input(expanded)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkYkVjFtqpIG"
      },
      "source": [
        "def format_img_vgg19(filename):\n",
        "  pic = load_img(filename, target_size=(224,224))\n",
        "  pic_arr = img_to_array(pic)\n",
        "  #expanded = np.expand_dims(pic_arr, axis=0)\n",
        "  expanded = pic_arr.reshape(1, pic_arr.shape[0], pic_arr.shape[1], pic_arr.shape[2])\n",
        "  return preprocess_input_vgg19(expanded)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hILeQtmTzyWv"
      },
      "source": [
        "# Load InceptionResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrug1XPDuuNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f9c46f-0178-4607-87b5-ad0b65b35619"
      },
      "source": [
        "%%time\n",
        "\n",
        "inception_model = InceptionResNetV2(weights='imagenet')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 4s 0us/step\n",
            "CPU times: user 6.66 s, sys: 754 ms, total: 7.41 s\n",
            "Wall time: 10.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vY-iNec0Ncg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "29f1ae09-a13a-432d-a78f-61d42ffd4d60"
      },
      "source": [
        "#inception_model.graph = tf.get_default_graph()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-78853ab1e154>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minception_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPiAWaQ1bXWT"
      },
      "source": [
        "# Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ck3IK6T161p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e039db-4d4b-49e3-b7a5-91bbfc074fb6"
      },
      "source": [
        "prediction = inception_model.predict(preprocessed)\n",
        "decode_predictions(prediction)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n03888257', 'parachute', 0.9195096),\n",
              "  ('n02782093', 'balloon', 0.0025252027),\n",
              "  ('n09428293', 'seashore', 0.0006698671),\n",
              "  ('n02692877', 'airship', 0.0005274453),\n",
              "  ('n09193705', 'alp', 0.00036097906)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPL0u9c1b79H"
      },
      "source": [
        "data = format_img_inceptionresnet('coffeemilk.jpg')\n",
        "prediction = inception_model.predict(data)\n",
        "display(load_img('coffeemilk.jpg'))\n",
        "decode_predictions(prediction)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuLK-fUCpN8Y"
      },
      "source": [
        "# Testing the VGG19 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbdn5KVKpf0u"
      },
      "source": [
        "VGG19 Model from Keras with the ImageNet weights to make a prediction on several of the sample images. Loads the model into the notebook. Process' the data for VGG19. Then makes a prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfUQ5j1Xpe0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51705903-2dda-4475-eaf2-e68002ffd685"
      },
      "source": [
        "vgg19_model = VGG19()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 9s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2FPrzeMkSJk"
      },
      "source": [
        "data = format_img_vgg19(FILE_3)\n",
        "pred = vgg19_model.predict(data)\n",
        "display(load_img(FILE_3))\n",
        "decode_vgg19(pred)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRZsFAn-wYwM"
      },
      "source": [
        "data = format_img_vgg19('baloons.jpg')\n",
        "pred = vgg19_model.predict(data)\n",
        "display(load_img('baloons.jpg'))\n",
        "decode_vgg19(pred)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNzr8tiwxS9b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}